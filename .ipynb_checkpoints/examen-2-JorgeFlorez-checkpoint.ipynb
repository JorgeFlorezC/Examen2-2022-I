{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examen 2 - Jorge Florez\n",
    "\n",
    "Page to be scraped: Alianza Verde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Solved deprecation warning: https://exerror.com/deprecationwarning-executable_path-has-been-deprecated-please-pass-in-a-service-object/\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.display import display,HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL of the site to be analyzed\n",
    "SITE_URL = 'https://alianzaverde.org.co/lideres-verdes/congreso-2022/senado-2022'\n",
    "ROOT_URL = 'https://alianzaverde.org.co'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the driver for you S.O. here: https://github.com/mozilla/geckodriver/releases\n",
    "\n",
    "# Firefox1 web driver path\n",
    "s1 = Service('./geckodriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request(browser):\n",
    "    # Making the request and rendering the browser\n",
    "    browser.get(SITE_URL)\n",
    "    \n",
    "    # Simulating vertical scrolling for handling lazy load\n",
    "    check_height = browser.execute_script('return document.body.scrollHeight;')\n",
    "    while True:\n",
    "        browser.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(3)\n",
    "        height = browser.execute_script('return document.body.scrollHeight;')\n",
    "        if height == check_height: \n",
    "            break \n",
    "        check_height = height\n",
    "    \n",
    "    # Getting HTML content and passing it to BeautifulSoup for scraping analysis\n",
    "    return BeautifulSoup(browser.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9096\\2275892990.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Getting HTML content from page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrowser_archive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Finding the section where candidates are contained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9096\\3034130412.py\u001b[0m in \u001b[0;36mmake_request\u001b[1;34m(browser)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'window.scrollTo(0, document.body.scrollHeight);'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'return document.body.scrollHeight;'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcheck_height\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating a firefox window\n",
    "browser_archive = webdriver.Firefox(service=s1)\n",
    "\n",
    "# Getting HTML content from page\n",
    "soup = make_request(browser_archive)\n",
    "\n",
    "# Finding the section where candidates are contained\n",
    "sections = soup.find_all(class_ = 'sppb-col-md-3')\n",
    "#print(len(sections))\n",
    "\n",
    "# Close the firefox window\n",
    "browser_archive.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a list for the candidates\n",
    "candidatos = []\n",
    "\n",
    "# Iterate over each section\n",
    "for section in sections:\n",
    "\n",
    "    # Avoiding sections without candidates\n",
    "    if section.find(class_ = 'person-content-show-on-hover') != None:\n",
    "        \n",
    "        \n",
    "        # Checking the social networks for candidate        \n",
    "        if section.find(class_ = 'sppb-person-social') != None:\n",
    "            social_networks = section.find(class_ = 'sppb-person-social').find_all('a')\n",
    "            \n",
    "            #Assign the standar valor of None to all social neworks previous to checking each one\n",
    "            facebook_link = None\n",
    "            twitter_link = None\n",
    "            youTube_link = None\n",
    "            instagram_link = None\n",
    "            \n",
    "        \n",
    "            #print(social_networks)\n",
    "\n",
    "            for social_net in social_networks:\n",
    "                #print(social_net)\n",
    "\n",
    "                #Get the Facebook url                \n",
    "                if social_net.attrs['aria-label'] == 'Facebook':\n",
    "                    facebook_link = social_net.attrs['href']\n",
    "\n",
    "\n",
    "                #Get the Twitter url\n",
    "                if social_net.attrs['aria-label'] == 'Twitter':\n",
    "                    twitter_link = social_net.attrs['href']\n",
    "\n",
    "\n",
    "                #Get the YouTube url                \n",
    "                if social_net.attrs['aria-label'] == 'YouTube':\n",
    "                    youTube_link = social_net.attrs['href']\n",
    "\n",
    "\n",
    "                #Get the Instagram url                \n",
    "                if social_net.attrs['aria-label'] == 'Instagram':\n",
    "                    instagram_link = social_net.attrs['href']\n",
    "\n",
    "\n",
    "\n",
    "        # Add the items to the list\n",
    "        candidatos.append({\n",
    "            #photo\n",
    "            'foto': ROOT_URL + section.find('img').attrs['src'],\n",
    "\n",
    "            #description     \n",
    "            'descripcion': section.find(class_ = 'sppb-person-designation').get_text(),\n",
    "\n",
    "            #facebook     \n",
    "            'facebook': facebook_link,\n",
    "\n",
    "            #twitter     \n",
    "            'twitter': twitter_link,\n",
    "\n",
    "            #youtube     \n",
    "            'youtube': youTube_link,\n",
    "\n",
    "            #instagram     \n",
    "            'instagram': instagram_link\n",
    "\n",
    "        })\n",
    "\n",
    "\n",
    "#len(candidatos)\n",
    "candidatos[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transforming extracted data to a tabular format\n",
    "candidatos_df = pd.DataFrame(candidatos)\n",
    "display(candidatos_df.loc[18:18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create function to show images on data frame\n",
    "# reference: https://stackoverflow.com/questions/53468558/adding-image-to-pandas-dataframe\n",
    "\n",
    "# convert your links to html tags \n",
    "def path_to_image_html(path):\n",
    "    return '<img src=\"'+ path + '\" width=\"100\" >'\n",
    "\n",
    "#Define which columns will be used to convert to html\n",
    "image_col = ['foto']\n",
    "\n",
    "# Create the dictionariy to be passed as formatters\n",
    "format_dict = {}\n",
    "for image in image_col:\n",
    "    format_dict[image] = path_to_image_html\n",
    "\n",
    "display(HTML(candidatos_df.to_html(escape=False ,formatters=format_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
